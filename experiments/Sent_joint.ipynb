{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2f8e78af7b04327bf9a9fa01c756510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_029210abf0b7412ab3473448d3a663af",
              "IPY_MODEL_4b3674d674704557b1954cfb83eba27b"
            ],
            "layout": "IPY_MODEL_ba238dbae68e44039ac51068ca7520cb"
          }
        },
        "029210abf0b7412ab3473448d3a663af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a5464973604d318402bec030947512",
            "placeholder": "​",
            "style": "IPY_MODEL_27cef956254a4d47a1c418286f0d40bb",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4b3674d674704557b1954cfb83eba27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fbb5d232ea646ca927bddac375be625",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97f605c11b514aa6a55aa6e170f630f7",
            "value": 1
          }
        },
        "ba238dbae68e44039ac51068ca7520cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a5464973604d318402bec030947512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27cef956254a4d47a1c418286f0d40bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fbb5d232ea646ca927bddac375be625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f605c11b514aa6a55aa6e170f630f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuliya1324/Aspect_Sent_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5Z4TNs6IAx",
        "outputId": "1a82f65b-d9be-4d16-c6f0-0aa9a8d695da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aspect_Sent_project'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 47 (delta 17), reused 33 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUGF0SLd6Hdn",
        "outputId": "83ffc125-36fd-4a08-e0a1-28445a91bcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 26.0 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 66.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 73.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 82.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 76.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 76.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 81.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 78.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 88.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 64.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 62.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 91.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 67.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3e55dea910d164df592202d84f7466514ae79f601a0bae33dae686c93da37a6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.7\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqiYZly2Smin",
        "outputId": "36644551-276d-42ef-d9b2-969f8599fda7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbroody_one\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "Z7gF5udm6IYl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "prwzHRw-b-b6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    RobertaTokenizerFast, \n",
        "    DataCollatorForTokenClassification,\n",
        "    AutoModelForTokenClassification, \n",
        "    TrainingArguments, \n",
        "    Trainer)"
      ],
      "metadata": {
        "id": "Vxb2F8Cts2xl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "AwNjGzmn1uQS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "set_random_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "     "
      ],
      "metadata": {
        "id": "jyFYWY2710WE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/Aspect_Sent_project/data/aspects_train.csv', index_col=0)\n",
        "df_va = pd.read_csv('/content/Aspect_Sent_project/data/aspects_val.csv', index_col=0)"
      ],
      "metadata": {
        "id": "ovStMVIr13ag"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_tr.groupby(\"idx\").agg(list)\n",
        "df_val = df_va.groupby(\"idx\").agg(list)"
      ],
      "metadata": {
        "id": "7VrtIFG9C_T5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'sberbank-ai/ruRoberta-large'\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 4"
      ],
      "metadata": {
        "id": "ispzvCui6Bob"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)"
      ],
      "metadata": {
        "id": "irgwypDXsjrs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JointDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.cat_to_int = {\n",
        "            \"O\": 0, \n",
        "            \"B-Food\": 1, \n",
        "            \"I-Food\": 2, \n",
        "            \"B-Interior\": 3,\n",
        "            \"I-Interior\": 4, \n",
        "            \"B-Price\": 5,\n",
        "            \"I-Price\": 6, \n",
        "            \"B-Whole\": 7, \n",
        "            \"I-Whole\": 8, \n",
        "            \"B-Service\": 9, \n",
        "            \"I-Service\": 10,\n",
        "            }\n",
        "        self.sent_to_int = {\"positive\": 0, \"negative\": 1, \"neutral\": 2, \"both\": 3}\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset[\"tokens\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokenized_inputs = self.tokenizer(self.dataset[\"tokens\"].iloc[idx], truncation=True, is_split_into_words=True, max_length=512, padding='max_length', return_tensors='pt')\n",
        "        cat_label = self.dataset[\"class\"].iloc[idx]\n",
        "        sent_label = self.dataset['sentiment'].iloc[idx]\n",
        "        word_ids = tokenized_inputs.word_ids()\n",
        "        previous_word_idx = None\n",
        "        cat_label_ids = []\n",
        "        sent_label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                cat_label_ids.append(-100)\n",
        "                sent_label_ids.append(-100)\n",
        "            else:\n",
        "                if cat_label[word_idx] == 'O':\n",
        "                    sent_label_ids.append(-100)\n",
        "                elif word_idx != previous_word_idx:\n",
        "                    sent_label_ids.append(self.sent_to_int[sent_label[word_idx]])\n",
        "                else:\n",
        "                    sent_label_ids.append(self.sent_to_int[sent_label[word_idx]])\n",
        "                if word_idx != previous_word_idx:\n",
        "                    cat_label_ids.append(self.cat_to_int[cat_label[word_idx]])\n",
        "                else:\n",
        "                    cat_label_ids.append(self.cat_to_int[cat_label[word_idx]])\n",
        "                \n",
        "            previous_word_idx = word_idx\n",
        "        tokenized_inputs[\"input_ids\"] = tokenized_inputs[\"input_ids\"].flatten()\n",
        "        tokenized_inputs[\"attention_mask\"] = tokenized_inputs[\"attention_mask\"].flatten()\n",
        "        tokenized_inputs[\"sent_labels\"] = torch.Tensor(sent_label_ids)\n",
        "        tokenized_inputs[\"cat_labels\"] = torch.Tensor(cat_label_ids)\n",
        "        return tokenized_inputs"
      ],
      "metadata": {
        "id": "g5hL7aajx0Vr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JointClassifier(nn.Module):\n",
        "  def __init__(self, n_cat, n_sent):\n",
        "        super(JointClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(MODEL_NAME, add_pooling_layer=False).to(device)\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "        self.Cat = nn.Linear(self.bert.config.hidden_size, n_cat).to(device)\n",
        "        self.Sent = nn.Linear(self.bert.config.hidden_size + n_cat, n_sent).to(device)\n",
        "  \n",
        "  def forward(self, batch):\n",
        "        outputs = self.bert(\n",
        "            input_ids=batch[\"input_ids\"].to(device),\n",
        "            attention_mask=batch[\"attention_mask\"].to(device)\n",
        "        )\n",
        "        cats = self.Cat(self.drop(outputs[0]))\n",
        "        outputs = self.Sent(torch.cat((outputs[0], cats), 2))\n",
        "        return {\n",
        "            \"cats\": cats,\n",
        "            \"sents\": outputs\n",
        "            }\n"
      ],
      "metadata": {
        "id": "LpeT-tnhz9pe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fidYTYQ71jfO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_model = JointClassifier(n_cat=11, n_sent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uI3yYrgCb8z",
        "outputId": "ff1661b7-c3f6-4b82-d861-88258157bd56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sberbank-ai/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_ds = JointDataset(df_train, tokenizer)\n",
        "va_ds = JointDataset(df_val, tokenizer)"
      ],
      "metadata": {
        "id": "9eTexFHUDcAy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_dl = DataLoader(tr_ds, batch_size=BATCH_SIZE)\n",
        "va_dl = DataLoader(va_ds, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "UTIlUJKZTnVm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,param in cur_model.named_parameters():\n",
        "    if not re.search(\"Sent|Cat|23|22|21|20\", name):\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "7vwal_gkYJOW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, cur_model.parameters()), lr=1e-5, correct_bias=False, weight_decay=0.06)\n",
        "total_steps = len(tr_dl) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0UAZUvDbz8h",
        "outputId": "200b78b0-b567-4d81-92e5-f5823e19612d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_loss(batch, pred):\n",
        "    cat_labs =  batch[\"cat_labels\"].type(torch.LongTensor)\n",
        "    sent_labs  = batch[\"sent_labels\"].type(torch.LongTensor)\n",
        "    loss1 = loss_fn(pred[\"cats\"].view(-1, pred[\"cats\"].size(2)), cat_labs.view(-1).to(device))\n",
        "    loss2 = loss_fn(pred[\"sents\"].view(-1, pred[\"sents\"].size(2)), sent_labs.view(-1).to(device))\n",
        "    return sum([loss1, loss2])"
      ],
      "metadata": {
        "id": "DQvXMOeHcFlm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(preds, labs):\n",
        "    res = {}\n",
        "    for key in preds.keys():\n",
        "        predictions = np.argmax(preds[key].to('cpu').detach().numpy(), axis=2).reshape((-1,))\n",
        "        labels = labs[key[:-1]+ '_labels'].reshape((-1,))\n",
        "\n",
        "        true_predictions = [p for (p, l) in zip(predictions, labels) if l != -100]\n",
        "        true_labels = [l for (p, l) in zip(predictions, labels) if l != -100]\n",
        "\n",
        "        accuracy = accuracy_score(true_labels, true_predictions)\n",
        "        res[key+\"accuracy\"] = accuracy\n",
        "    return res"
      ],
      "metadata": {
        "id": "lk3iPlpWcuER"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "):\n",
        "  model = model.train()\n",
        "  \n",
        "  for batch in data_loader:\n",
        "    pred = model(batch)\n",
        "    loss = count_loss(batch, pred) \n",
        "    score = compute_metrics(pred, batch)\n",
        "    score[\"train/loss\"] = loss.item()\n",
        "    wandb.log(score)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "def eval_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    true = {\n",
        "            \"cat_labels\": torch.tensor([]), \n",
        "            \"sent_labels\": torch.tensor([]),  \n",
        "            }\n",
        "    predictions = {\n",
        "            \"cats\": torch.tensor([]), \n",
        "            \"sents\": torch.tensor([]), \n",
        "            }\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            pred = model(batch)\n",
        "            loss = count_loss(batch, pred)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            for k in predictions:\n",
        "                true[k[:-1]+'_labels'] = torch.cat((true[k[:-1]+'_labels'], batch[k[:-1]+'_labels'].cpu()))\n",
        "                predictions[k] = torch.cat((predictions[k], pred[k].cpu()))\n",
        "\n",
        "    score = compute_metrics(predictions, true)\n",
        "    score[\"eval/loss\"] = np.mean(losses)\n",
        "    wandb.log(score)"
      ],
      "metadata": {
        "id": "euPRpEnhmqMN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"Sent_aspect\",\n",
        "    name=f\"experiment_{2}\",\n",
        "    )\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_epoch(\n",
        "        cur_model, \n",
        "        tr_dl, \n",
        "        optimizer, \n",
        "        device, \n",
        "        scheduler, \n",
        "        )\n",
        "    eval_model(cur_model, va_dl, device)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "e2f8e78af7b04327bf9a9fa01c756510",
            "029210abf0b7412ab3473448d3a663af",
            "4b3674d674704557b1954cfb83eba27b",
            "ba238dbae68e44039ac51068ca7520cb",
            "92a5464973604d318402bec030947512",
            "27cef956254a4d47a1c418286f0d40bb",
            "7fbb5d232ea646ca927bddac375be625",
            "97f605c11b514aa6a55aa6e170f630f7"
          ]
        },
        "id": "U1Q8fJU_zXk4",
        "outputId": "2434c3d2-36e4-4ba2-cf98-5b4d7ccd8e79"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:3hcbpgmi) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2f8e78af7b04327bf9a9fa01c756510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>catsaccuracy</td><td>▆█▆▄▇▅▁█</td></tr><tr><td>sentsaccuracy</td><td>█▆▆▅▁█▇▄</td></tr><tr><td>train/loss</td><td>▁▃▃▄█▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>catsaccuracy</td><td>0.86496</td></tr><tr><td>sentsaccuracy</td><td>0.50806</td></tr><tr><td>train/loss</td><td>1.60658</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">experiment_2</strong>: <a href=\"https://wandb.ai/broody_one/Sent_aspect/runs/3hcbpgmi\" target=\"_blank\">https://wandb.ai/broody_one/Sent_aspect/runs/3hcbpgmi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221226_085742-3hcbpgmi/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:3hcbpgmi). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221226_085810-32ncdf42</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/broody_one/Sent_aspect/runs/32ncdf42\" target=\"_blank\">experiment_2</a></strong> to <a href=\"https://wandb.ai/broody_one/Sent_aspect\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>catsaccuracy</td><td>▅▃▄▄▇▁▇▄▆▆▆▆▆▆▆▅█▅▆▅▇▄▅▅▇▆▅▆▆█▇▆█▅▅▅█▄▆▆</td></tr><tr><td>eval/loss</td><td>█▆▆▄▂▂▁▁▁▁</td></tr><tr><td>sentsaccuracy</td><td>▃▅▆▁▆▆▃▇▄█▄▆▅▆▆▄▃▆▆▃▇▆▆▇▄█▅▆▆▇▇▆▄▅▇▅▇▇▇█</td></tr><tr><td>train/loss</td><td>▅▅▄█▃▅▆▃▂▄▅▃▄▅▂▃▄▁▅▃▂▃▃▃▂▂▂▄▂▄▄▂▃▄▂▄▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>catsaccuracy</td><td>0.90684</td></tr><tr><td>eval/loss</td><td>0.90148</td></tr><tr><td>sentsaccuracy</td><td>0.77607</td></tr><tr><td>train/loss</td><td>0.74661</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">experiment_2</strong>: <a href=\"https://wandb.ai/broody_one/Sent_aspect/runs/32ncdf42\" target=\"_blank\">https://wandb.ai/broody_one/Sent_aspect/runs/32ncdf42</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221226_085810-32ncdf42/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cur_model, \"model_joint.pt\")"
      ],
      "metadata": {
        "id": "EwgNyJNDogFC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/serve.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh7Q9ZlksrRO",
        "outputId": "833f21b9-d158-4569-e5ea-046b1b0e0dbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'serve'...\n",
            "remote: Enumerating objects: 34841, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 34841 (delta 63), reused 109 (delta 53), pack-reused 34698\u001b[K\n",
            "Receiving objects: 100% (34841/34841), 65.78 MiB | 7.42 MiB/s, done.\n",
            "Resolving deltas: 100% (20964/20964), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver --model-name cur_model --version 1.0 --serialized-file model_joint.pt --handler text_classifier --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEPR_UUitUeD",
        "outputId": "9c268289-828e-4a2b-b8b0-d8d970a978b9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING - Overwriting /content/cur_model.mar ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-model-archiver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In2PgIVItodb",
        "outputId": "60b4102a-58e1-41d2-dd8d-c1bb918015a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-model-archiver\n",
            "  Downloading torch_model_archiver-0.7.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch-model-archiver) (0.16.0)\n",
            "Collecting enum-compat\n",
            "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
            "Installing collected packages: enum-compat, torch-model-archiver\n",
            "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch-model-archiver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "8YSD-9NIt3pl",
        "outputId": "7e947043-383a-4722-97d5-ac4ca3397b72"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-edfb9d23f7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0marchiver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7jsTgF-t9qD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}